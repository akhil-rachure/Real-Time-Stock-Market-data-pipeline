# Real-Time-Stock-Market-data-pipeline

## Project Overview
In this real-time stock market data engineering project, I utilized Apache Kafka as the central component for a robust data pipeline. Leveraging Python, AWS (S3, Athena, Glue Crawler, EC2), the goal was to enable real-time data streaming and processing, emphasizing operational aspects in data engineering to build End-to-End data pipeline.

## Technology Used
* Python – Serving as the core of our data processing operations.
* Amazon Web Services (AWS) – For robust and scalable cloud infrastructure.
* Apache Kafka – Core of the project, enabling real-time data streaming and processing.
* AWS S3 (Simple Storage Service) – Employed for secure and dependable data storage.
* AWS Athena & Glue Crawler – Leveraged for efficient data querying and cataloging.
* AWS EC2 – Used for accessing powerful and scalable computing capacity in the cloud.

## Infrastructure Diagram:
<img width="835" alt="Architecture" src="https://github.com/akhil-rachure/Real-Time-Stock-Market-data-pipeline/assets/25721124/bb9b83de-c680-47c4-81f2-a200f4af68af">
